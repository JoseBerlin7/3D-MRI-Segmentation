{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba8c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs  Users  projects\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e22c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/e4ds-v4/code/Users/jose.d.berlin/3D-MRI-Segmentation\n"
     ]
    }
   ],
   "source": [
    "%cd Users/jose.d.berlin/3D-MRI-Segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2aa50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42mNotebooks\u001b[0m/  \u001b[01;32mREADME.md\u001b[0m*  \u001b[34;42mdata\u001b[0m/  \u001b[34;42mmodels\u001b[0m/  \u001b[34;42msrc\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520c7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf3584c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "sample = nib.load(\"data/mpr-1.nifti.img\")\n",
    "sample_in = torch.tensor(sample.get_fdata()).float().squeeze(3).unsqueeze(0).unsqueeze(0)\n",
    "print(sample_in.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb77cc7",
   "metadata": {},
   "source": [
    "### Patch Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae59c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size, patch_size, in_chans, embed_dim):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.D, self.H, self.W = img_size\n",
    "        self.pD, self.pH, self.pW = patch_size\n",
    "\n",
    "        assert self.D % self.pD == 0 and self.H % self.pH == 0 and self.W % self.pW == 0, \"Image dimensions must be divisible by the patch size.\"\n",
    "\n",
    "        self.num_patches = (self.D // self.pD) * (self.H // self.pH) * (self.W // self.pW)\n",
    "        self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"input:\",x.shape)\n",
    "        x = self.proj(x)  # B, embed_dim, D//pD, H//pH, W//pW\n",
    "        B, C, Dp, Hp, Wp = x.shape\n",
    "        print(\"bef:\",x.shape)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        print(\"aft:\",x.shape)\n",
    "        x = x.view(B, -1, C)  # B, N, C\n",
    "        print(\"view:\",x.shape)\n",
    "        x = self.norm(x)\n",
    "        print(\"norm:\",x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6aac5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinUNETR3D(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_ch=1, \n",
    "        out_ch=1, \n",
    "        img_size=(128, 128, 128), \n",
    "        patch_size=(4, 4, 4), \n",
    "        window_size=(7, 7, 7), \n",
    "        embed_dim=96, \n",
    "        depths=(2, 2, 2, 2), \n",
    "        num_heads=(2, 4, 8, 16),\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=True,\n",
    "        drop_rate=0.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        drop_path_rate=0.0\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_ch,\n",
    "            embed_dim=embed_dim\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0] # Batch size\n",
    "\n",
    "        x_tokens = self.patch_embed(x)\n",
    "        return x_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d19312b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "swin = SwinUNETR3D(in_ch=1, out_ch=1, img_size=sample_in.shape[2:], embed_dim=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46871a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 1, 256, 256, 128])\n",
      "bef: torch.Size([1, 96, 64, 64, 32])\n",
      "aft: torch.Size([1, 64, 64, 32, 96])\n",
      "view: torch.Size([1, 131072, 96])\n",
      "norm: torch.Size([1, 131072, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5086,  0.5042, -0.4807,  ...,  0.5815, -0.0622,  0.1525],\n",
       "         [-1.4675,  0.4533,  0.6392,  ...,  0.4482, -0.0679,  0.0435],\n",
       "         [-1.4159,  0.8678, -0.7656,  ...,  0.2521,  0.7943,  0.7551],\n",
       "         ...,\n",
       "         [-0.9434,  1.2161,  0.2173,  ...,  0.0936, -0.1224,  0.6493],\n",
       "         [-1.6088,  0.5546,  0.6410,  ..., -0.0180, -0.1719,  0.7827],\n",
       "         [-0.4031, -0.0071, -0.5993,  ...,  0.5524, -0.3631,  1.0740]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin(sample_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1791ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
